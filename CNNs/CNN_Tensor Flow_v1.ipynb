{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of a Convolution Neural Network in Tensorflow\n",
    "author : m.mahyar_ali ......date_created : April,2,2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import Libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_h,n_w,n_c,n_y):\n",
    "    '''n_h : Height of filter matrix\n",
    "       n_w : width of filter matrix\n",
    "       n_c : Depth of the filter matrix\n",
    "       n_y : Size of output layer'''\n",
    "    #None is used for number of training examples,so that we can change it later\n",
    "    X = tf.placeholder(tf.float32,shape=(None,n_h,n_w,n_c))\n",
    "    Y = tf.placeholder(tf.float32,shape=(None,n_y))\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    '''\n",
    "    We are using eight filters of 4*4 sie at CONV1 or layer 1\n",
    "    W1 : [4, 4, 3, 8]\n",
    "    \n",
    "    We are using 16 filters of 2*2 size at layer 2 or CONV2\n",
    "    W2 : [2, 2, 8, 16] \n",
    "    '''\n",
    "    tf.set_random_seed(1)  #For Testing Purpose\n",
    "    W1 = tf.get_variable('W1',[4, 4, 3, 8],initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W2 = tf.get_variable('W2',[2, 2, 8, 16],initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    \n",
    "    parameters={'W1':W1,'W2':W2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In detail, we will use the following parameters for all the steps:\n",
    " - Conv2D: stride 1, padding is \"SAME\"\n",
    " - ReLU\n",
    " - Max pool: Use an 8 by 8 filter size and an 8 by 8 stride, padding is \"SAME\"\n",
    " - Conv2D: stride 1, padding is \"SAME\"\n",
    " - ReLU\n",
    " - Max pool: Use a 4 by 4 filter size and a 4 by 4 stride, padding is \"SAME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X,parameters):\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    \n",
    "    Z1 = tf.nn.conv2d(X,W1,strides=[1,1,1,1],padding=\"SAME\")\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    P1 = tf.nn.max_pool(A1,ksize=[1,8,8,1],strides=[1,8,8,1],padding=\"SAME\")\n",
    "    \n",
    "    Z2 = tf.nn.conv2d(P1,W2,strides=[1,1,1,1],padding='SAME')\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    P2 = tf.nn.max_pool(A2,ksize=[1,4,4,1],strides=[1,4,4,1],padding='SAME')\n",
    "    \n",
    "    F = tf.contrib.layers.flatten(P2)\n",
    "    \n",
    "    Z3 = tf.contrib.layers.fully_connected(F,6,activation_fn = None)\n",
    "    #Cost Function will automatically compute the actiavtions\n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Z3,Y):\n",
    "    \n",
    "    cost= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z3,labels=Y))\n",
    "    \n",
    "    return cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X_tarin,Y_train,minibatch_sizde,seed):\n",
    "    np.random.seed(seed) ;\n",
    "    m = X_train.shape[0] \n",
    "    \n",
    "    #According to this case\n",
    "    random_perm = list(np.random.perm(m))\n",
    "    X_train = X_train[random_perm,:,:,3]\n",
    "    Y_train = Y_train[random_perm,:]\n",
    "    \n",
    "    num_minibatches = int(m / minibatch_size)\n",
    "    minibatches = []\n",
    "    for batch in range(num_minibatches):\n",
    "        minibatch_X = X_train[batch*minibatch_size:minibatch_size(batch+1),:,:,:]\n",
    "        minibatch_Y = Y_train[batch*minibatch_size:minibatch_size(batch+1),:,:,:]\n",
    "        minibatches.append((minibatch_X,minibatch_Y))\n",
    "        \n",
    "    # For thehttps://mpgntkofxqkwukrnvbolrk.coursera-apps.org/notebooks/week1/Untitled.ipynb?kernel_name=python3# last incomplete mini batch\n",
    "    \n",
    "    if m%minibatch_size != 0 :\n",
    "        minibatch_X = X_train[minibatch_size*num_minibatches:,:,:,:]\n",
    "        minibatch_Y = Y_train[minibatch_size*num_minibatches:,:,:,:]\n",
    "        \n",
    "        minibatch_Y = Y_train[batch*minibatch_size:minibatch_size(batch+1),:,:,:]\n",
    "        minibatches.append((minibatch_X,minibatch_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train,Y_train,X_test,Y_test,learning_rate = 0.009,num_epoch=100,minibatch_size = 64,print_cost=True):\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n",
    "    seed = 3                                          # to keep results consistent (numpy seed)\n",
    "    costs = []\n",
    "    \n",
    "    (m, n_h, n_w,n_c) = X_train.shape\n",
    "    n_y = Y_train.shape[1]\n",
    "    X ,Y = create_placeholders(n_h,n_w,n_c,n_y)\n",
    "    \n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    Z3 = forward_propagation(X,parameters)\n",
    "    \n",
    "    cost = compute_cost(Z3,Y)\n",
    "    \n",
    "    optimizer= tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        \n",
    "        for epoch in range(num_epoch):\n",
    "            minibatch_cost = 0\n",
    "            seed = seed+1\n",
    "            num_minibatches = int(m / minibatch_size)\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "            for minibatch in minibatches:\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                _,temp_cost = sess.run([optimizer,cost],feed_dict = {X:minibatch_X,Y:minibatch_Y})\n",
    "                \n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "                \n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "            \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
